{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae5ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scam JSON:\n",
      "{\n",
      "    \"caption\": \"A text message alert from HSBC regarding unusual activity in a bank account, urging the recipient to visit a provided link.\",\n",
      "    \"tags\": [\n",
      "        \"HSBC\",\n",
      "        \"bank\",\n",
      "        \"text message\",\n",
      "        \"scam\",\n",
      "        \"phishing\"\n",
      "    ],\n",
      "    \"scam_type\": \"phishing\",\n",
      "    \"category\": \"Fraud\"\n",
      "}\n",
      "\n",
      "ðŸŽ¬ Generated Script:\n",
      " Scene:\n",
      "[Interior of a chaotic Italian household, with classic Italian Brain Rot characters Nonna Maria and Luigi sitting at the kitchen table.]\n",
      "\n",
      "Nonna Maria: *reading text message alert* \"Eh?! Luigi, HSBC says there's unusual activity in our bank account! We must click this link, pronto!\"\n",
      "\n",
      "Luigi: *frantically waving hands* \"No, Nonna! It's-a scam! Don't click, don't click!\"\n",
      "\n",
      "Nonna Maria: *ignoring Luigi and clicking the link* \"Mamma mia, let's see what's inside!\"\n",
      "\n",
      "[Cut to a close-up of the computer screen showing a cartoonish scam message.]\n",
      "\n",
      "Scam Message: \"You win-a free spaghetti dinner! Just give us-a your bank details!\"\n",
      "\n",
      "[Nonna Maria's eyes widen in excitement, while Luigi facepalms in disbelief.]\n",
      "\n",
      "Luigi: *facepalming* \"Ay-ay-ay, Nonna...\"\n",
      "\n",
      "[End scene with Nonna Maria happily typing in her bank details as Luigi shakes his head in the background.]\n",
      "\n",
      "ðŸŽ¤ Narration Text for 11Labs:\n",
      " Nonna Maria: \"HSBC says there's unusual activity! Let's click, pronto!\"\n",
      "\n",
      "Luigi: \"No, Nonna! It's-a scam! Don't click!\"\n",
      "\n",
      "Nonna Maria: *clicks* \"Mamma mia, let's see what's inside!\"\n",
      "\n",
      "Scam Message: \"You win-a free spaghetti dinner! Give us-a your bank details!\"\n",
      "\n",
      "Luigi: \"Ay-ay-ay, Nonna...\"\n",
      "\n",
      "Nonna Maria: \"Free spaghetti? Grazie, scammers!\"\n",
      "Generated Brain Rot image saved at: brainrot.png\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from elevenlabs.play import play\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# -----------------------------\n",
    "# Function Definitions\n",
    "# -----------------------------\n",
    "\n",
    "def encode_image_to_base64(image_path: str) -> str:\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "def generate_json(img_base64: str) -> dict:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an assistant. Analyze the given image and generate a short, neutral description. \"\n",
    "                \"Return caption, tags, scam_type, and category in valid JSON format ONLY. \"\n",
    "                \"Do NOT include any explanations, extra text, or emojis. \"\n",
    "                \"The JSON must have keys: caption, tags, scam_type, category. \"\n",
    "                \"If scam_type is not applicable, set it to 'Unknown'.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    raw_output = response.choices[0].message.content\n",
    "    match = re.search(r\"\\{.*\\}\", raw_output, re.DOTALL)\n",
    "    json_text = match.group() if match else \"{}\"\n",
    "\n",
    "    try:\n",
    "        result = json.loads(json_text)\n",
    "    except json.JSONDecodeError:\n",
    "        result = {\"caption\": raw_output, \"tags\": [], \"scam_type\": \"Unknown\", \"category\": \"Unknown\"}\n",
    "\n",
    "    # Ensure all keys exist\n",
    "    result = {\n",
    "        \"caption\": result.get(\"caption\", \"\"),\n",
    "        \"tags\": result.get(\"tags\", []),\n",
    "        \"scam_type\": result.get(\"scam_type\", \"Unknown\"),\n",
    "        \"category\": result.get(\"category\", \"Unknown\")\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "def generate_brainrot_image(caption: str, output_path=\"brainrot.png\"):\n",
    "    \"\"\"\n",
    "    Generate an Italian Brain Rot meme image in English with 3D rendered Italian Brain Rot characters.\n",
    "    No bright colors, keep the scene coherent and humorous.\n",
    "    No text from the script should appear on the image. If any text is present, it must be coherent, sharp, and not deformed.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"Create a humorous Italian Brain Rot meme scene in English. \"\n",
    "        f\"Include 3D rendered characters juxtaposed together in absurd combinations. \"\n",
    "        f\"Do NOT use bright colors; use muted, realistic tones. \"\n",
    "        f\"The scene should visually reflect the caption/script: '{caption}', \"\n",
    "        f\"but do NOT include any text from the script on the image. \"\n",
    "        f\"If any text appears, it must be coherent, sharp, and not deformed. \"\n",
    "        f\"Keep it visually coherent and funny, like a surreal meme, without chaotic elements.\"\n",
    "    )\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1024\",\n",
    "        response_format=\"b64_json\"  # ensures we get base64 to save locally\n",
    "    )\n",
    "\n",
    "    image_b64 = response.data[0].b64_json\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(base64.b64decode(image_b64))\n",
    "\n",
    "    return output_path\n",
    "\n",
    "def generate_meme_script(meme_json: dict) -> str:\n",
    "    \"\"\"\n",
    "    Generates a meme script in the Italian Brain Rot style for an 8-second video.\n",
    "    The script should be funny, absurd, and feature classic Brain Rot characters,\n",
    "    but the scene should be visually coherent and not overly chaotic.\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "    prompt = (\n",
    "        \"You are a meme scriptwriter specializing in the ITALIAN BRAIN ROT style.\\n\"\n",
    "        \"Your task is to write a script for a short, 8-second meme video.\\n\"\n",
    "        \"Requirements:\\n\"\n",
    "        \"- Use classic Italian Brain Rot meme characters and personalities.\\n\"\n",
    "        \"- Make the scene funny and absurd, but keep it visually coherent and easy to follow.\\n\"\n",
    "        \"- Include exaggerated reactions and ridiculous dialogue, but avoid excessive chaos or randomness.\\n\"\n",
    "        \"- Keep the style consistent with Italian Brain Rot memes.\\n\"\n",
    "        \"- Only return the script text, no JSON or metadata.\\n\"\n",
    "        f\"\\nMeme details:\\n{meme_json}\\n\"\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content.strip()\n",
    "\n",
    "def generate_meme_narration(script_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a meme script into a funny, coherent narration for a 15-second video.\n",
    "    The narration is energetic, uses variable expression tones, and humorous, but does not reference any characters, user, original prompt, or generate sound effects.\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \n",
    "         \"You are a narration assistant for ITALIAN BRAIN ROT memes.\\n\"\n",
    "         \"Transform the given script into a humorous, energetic, and coherent narration for a 15-second video.\\n\"\n",
    "         \"Requirements:\\n\"\n",
    "         \"- Make the narration easy to follow and visually coherent.\\n\"\n",
    "         \"- Use variable expression tones to make the narration dynamic and engaging.\\n\"\n",
    "         \"- Add meme punchlines and absurd comments, but do not reference any characters, user, original prompt, or generate sound effects.\\n\"\n",
    "         \"- Do not include captions, emojis, formatting, or sound effects. Only plain, funny text.\"),\n",
    "        (\"user\", \"Convert this script into a narration in the Italian Brain Rot style:\\n\\n{script}\")\n",
    "    ])\n",
    "    messages = prompt_template.format_messages(script=script_text)\n",
    "    response = llm.invoke(messages)\n",
    "    return response.content.strip()\n",
    "\n",
    "\n",
    "def generate_and_play_audio(narration: str, voice_id: str = \"pNInz6obpgDQGcFmaJgB\"):\n",
    "    elevenlabs = ElevenLabs(api_key=os.getenv(\"ELEVENLABS_API_KEY\"))\n",
    "    audio = elevenlabs.text_to_speech.convert(\n",
    "        text=narration,\n",
    "        voice_id=voice_id,\n",
    "        model_id=\"eleven_multilingual_v2\",\n",
    "        output_format=\"mp3_44100_128\",\n",
    "    )\n",
    "    play(audio)\n",
    "\n",
    "# -----------------------------\n",
    "# Main Pipeline\n",
    "# -----------------------------\n",
    "def main():\n",
    "    img_base64 = encode_image_to_base64(\"user_upload.jpg\")\n",
    "    scam_json = generate_json(img_base64)\n",
    "    print(\"âœ… Scam JSON:\")\n",
    "    print(json.dumps(scam_json, indent=4))\n",
    "\n",
    "    script_text = generate_meme_script(scam_json)\n",
    "    print(\"\\nðŸŽ¬ Generated Script:\\n\", script_text)\n",
    "    \n",
    "    narration = generate_meme_narration(script_text)\n",
    "    print(\"\\nðŸŽ¤ Narration Text for 11Labs:\\n\", narration)\n",
    "\n",
    "    image_file = generate_brainrot_image(script_text)\n",
    "    print(\"Generated Brain Rot image saved at:\", image_file)\n",
    "    \n",
    "    generate_and_play_audio(narration)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b62b3b54",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scam_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Step 1: Generate replay script\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m replay_script = generate_replay_script(\u001b[43mscam_json\u001b[49m)\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸŽ¬ Replay Script:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, replay_script)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Step 2: Generate narration and visual annotations\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'scam_json' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import json\n",
    "\n",
    "def generate_replay_script(scam_json: dict) -> str:\n",
    "    \"\"\"\n",
    "    Generates an 8-12 second neutral, serious educational replay script based on the scam JSON.\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "    \n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         \"You are an educational assistant. \"\n",
    "         \"Generate a short, clear, and serious script explaining how a scam or misleading content works. \"\n",
    "         \"Describe step-by-step actions and potential consequences in a factual and neutral tone. \"\n",
    "         \"Keep it concise (8-12 seconds) and return ONLY the script text, no JSON, humor, or exaggeration.\"),\n",
    "        (\"user\",\n",
    "         \"Use the following scam JSON to write the educational replay script:\\n\\n{scam_json}\")\n",
    "    ])\n",
    "\n",
    "    messages = prompt_template.format_messages(scam_json=json.dumps(scam_json, indent=2))\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return response.content.strip()\n",
    "\n",
    "\n",
    "def generate_narration_and_annotations(replay_script: str, scam_json: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Generates neutral narration text for TTS and factual visual annotations for the replay.\n",
    "    Returns a dictionary with 'narration_text' and 'visual_annotations'.\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "    \n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         \"You are a narration assistant for educational videos. \"\n",
    "         \"Rewrite the replay script into clear, neutral, and serious narration suitable for TTS. \"\n",
    "         \"Also generate visual annotation suggestions that highlight scam cues or manipulation points in a factual way. \"\n",
    "         \"Return in JSON with keys: narration_text (string), visual_annotations (list of strings).\"),\n",
    "        (\"user\",\n",
    "         \"Replay Script:\\n{replay_script}\\n\\nScam JSON:\\n{scam_json}\")\n",
    "    ])\n",
    "    \n",
    "    messages = prompt_template.format_messages(\n",
    "        replay_script=replay_script,\n",
    "        scam_json=json.dumps(scam_json, indent=2)\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Attempt to parse JSON safely\n",
    "    try:\n",
    "        output = json.loads(response.content.strip())\n",
    "    except json.JSONDecodeError:\n",
    "        output = {\n",
    "            \"narration_text\": response.content.strip(),\n",
    "            \"visual_annotations\": []\n",
    "        }\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Step 1: Generate replay script\n",
    "replay_script = generate_replay_script(scam_json)\n",
    "print(\"ðŸŽ¬ Replay Script:\\n\", replay_script)\n",
    "\n",
    "# Step 2: Generate narration and visual annotations\n",
    "narration_output = generate_narration_and_annotations(replay_script, scam_json)\n",
    "print(\"ðŸŽ¤ Narration:\\n\", narration_output['narration_text'])\n",
    "print(\"ðŸ–Œï¸ Annotations:\\n\", narration_output['visual_annotations'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e32778b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤ Narration Text for 11Labs:\n",
      " Cautious Citizen just got a text alert from HSBC asking for their details. With a sly smirk, they peek over their sunglasses and type carefully, saying, \"Nice try, Phish Bond.\" Remember to stay sharp!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     30\u001b[39m elevenlabs = ElevenLabs(\n\u001b[32m     31\u001b[39m   api_key=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mELEVENLABS_API_KEY\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     32\u001b[39m )\n\u001b[32m     34\u001b[39m audio = elevenlabs.text_to_speech.convert(\n\u001b[32m     35\u001b[39m     text= narration ,\n\u001b[32m     36\u001b[39m     voice_id=\u001b[33m\"\u001b[39m\u001b[33mJBFqnCBsd6RMkjVDRZzb\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m     model_id=\u001b[33m\"\u001b[39m\u001b[33meleven_multilingual_v2\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m     output_format=\u001b[33m\"\u001b[39m\u001b[33mmp3_44100_128\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     39\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TruthLoop/truthloop/lib/python3.13/site-packages/elevenlabs/play.py:45\u001b[39m, in \u001b[36mplay\u001b[39m\u001b[34m(audio, notebook, use_ffmpeg)\u001b[39m\n\u001b[32m     38\u001b[39m     args = [\u001b[33m\"\u001b[39m\u001b[33mffplay\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m-autoexit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m-nodisp\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     39\u001b[39m     proc = subprocess.Popen(\n\u001b[32m     40\u001b[39m         args=args,\n\u001b[32m     41\u001b[39m         stdout=subprocess.PIPE,\n\u001b[32m     42\u001b[39m         stdin=subprocess.PIPE,\n\u001b[32m     43\u001b[39m         stderr=subprocess.PIPE,\n\u001b[32m     44\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     out, err = \u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     proc.poll()\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/subprocess.py:1222\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1219\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1221\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1224\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1225\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/subprocess.py:2128\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   2121\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout,\n\u001b[32m   2122\u001b[39m                         stdout, stderr,\n\u001b[32m   2123\u001b[39m                         skip_check_and_raise=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2124\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[32m   2125\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2126\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfailed to raise TimeoutExpired.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2128\u001b[39m ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[32m   2131\u001b[39m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[32m   2132\u001b[39m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/selectors.py:398\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    396\u001b[39m ready = []\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from elevenlabs.play import play\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# LLM setup\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# Narration bot prompt\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are a narration assistant. Rewrite scripts into smooth, human-like narration \"\n",
    "     \"for a short 15-second video. Keep it conversational and easy for TTS. \"\n",
    "     \"Do NOT include stage directions, emojis, or formatting. Just plain narration text.\"),\n",
    "    (\"user\", \"Convert this script into narration:\\n\\n{script}\")\n",
    "])\n",
    "\n",
    "# Format and run\n",
    "messages = prompt_template.format_messages(script=script_text)\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "narration = response.content.strip()\n",
    "\n",
    "print(\"ðŸŽ¤ Narration Text for 11Labs:\\n\", narration)\n",
    "\n",
    "elevenlabs = ElevenLabs(\n",
    "  api_key=os.getenv(\"ELEVENLABS_API_KEY\"),\n",
    ")\n",
    "\n",
    "audio = elevenlabs.text_to_speech.convert(\n",
    "    text= narration ,\n",
    "    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n",
    "    model_id=\"eleven_multilingual_v2\",\n",
    "    output_format=\"mp3_44100_128\",\n",
    ")\n",
    "\n",
    "play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ce114",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error code: 403 - {'error': 'Model variant gen4_image is not available', 'docUrl': 'https://docs.dev.runwayml.com/api'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionDeniedError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# The env var RUNWAYML_API_SECRET is expected to contain your API key.\u001b[39;00m\n\u001b[32m      4\u001b[39m client = RunwayML()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m task = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage_to_video\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgen4_image\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m  \u001b[49m\u001b[43mprompt_image\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttps://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTZouypNVCAMcyEZHJ_I1l1kiyut3KdrVvkTg&s\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m  \u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mThe bunny is eating a carrot\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m  \u001b[49m\u001b[43mratio\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1280:720\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m.wait_for_task_output()\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(task)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TruthLoop/truthloop/lib/python3.13/site-packages/runwayml/resources/image_to_video.py:124\u001b[39m, in \u001b[36mImageToVideoResource.create\u001b[39m\u001b[34m(self, model, prompt_image, ratio, content_moderation, duration, prompt_text, seed, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m     54\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     55\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m     69\u001b[39m ) -> NewTaskCreatedResponse:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    This endpoint will start a new task to generate a video from an image prompt.\u001b[39;00m\n\u001b[32m     72\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    122\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/image_to_video\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_image\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mratio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent_moderation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_moderation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mduration\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimage_to_video_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageToVideoCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcreate_waitable_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mImageToVideoCreateResponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TruthLoop/truthloop/lib/python3.13/site-packages/runwayml/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TruthLoop/truthloop/lib/python3.13/site-packages/runwayml/_base_client.py:1044\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1041\u001b[39m             err.response.read()\n\u001b[32m   1043\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mPermissionDeniedError\u001b[39m: Error code: 403 - {'error': 'Model variant gen4_image is not available', 'docUrl': 'https://docs.dev.runwayml.com/api'}"
     ]
    }
   ],
   "source": [
    "from runwayml import RunwayML\n",
    "\n",
    "# The env var RUNWAYML_API_SECRET is expected to contain your API key.\n",
    "client = RunwayML()\n",
    "\n",
    "task = client.image_to_video.create(\n",
    "  model='gen4_turbo',\n",
    "  prompt_image='https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTZouypNVCAMcyEZHJ_I1l1kiyut3KdrVvkTg&s',\n",
    "  prompt_text='The bunny is eating a carrot',\n",
    "  ratio='1280:720',\n",
    ").wait_for_task_output()\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d679badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When you get a text from your 'bank' but you haven't even opened an account yet. | Tags: scam, phishing, funny, textmessage | Character: Confused User | Scam Type: Phishing\n"
     ]
    }
   ],
   "source": [
    "text_entry = f\"{result['caption']} | Tags: {', '.join(result['tags'])} | Character: {result['character']} | Scam Type: {result['scam_type']}\"\n",
    "print(text_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "628e89fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector = embeddings.embed_query(text_entry) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "901e510f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Meme stored in vector DB\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Initialize or load DB\n",
    "db = Chroma(persist_directory=\"meme_db\", embedding_function=embeddings)\n",
    "\n",
    "# Add the new meme\n",
    "db.add_texts([text_entry])\n",
    "db.persist()\n",
    "\n",
    "print(\"âœ… Meme stored in vector DB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "truthloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
