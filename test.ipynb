{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ae5ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"caption\": \"When you realize that 'unusual activity' is just your cat stepping on your phone.\",\n",
      "    \"tags\": [\n",
      "        \"scam\",\n",
      "        \"funny\",\n",
      "        \"cat\",\n",
      "        \"textmessage\"\n",
      "    ],\n",
      "    \"character\": \"Cat\",\n",
      "    \"scam_type\": \"Phishing\"\n",
      "}\n",
      "ðŸŽ¬ Generated Script:\n",
      " [Scene: A close-up of a phone screen with a notification: \"Unusual activity detected.\"]\n",
      "\n",
      "[Cut to: A cat sitting on the phone, looking innocent.]\n",
      "\n",
      "Text Overlay: \"Security Alert! ðŸš¨\"\n",
      "\n",
      "Cat (voiceover): \"I just wanted to order more treats...\"\n",
      "\n",
      "[Cut to: Person picking up the phone, shaking their head and smiling.]\n",
      "\n",
      "Person (laughing): \"Busted, Mr. Whiskers!\"\n",
      "\n",
      "[End scene with the cat giving a playful meow.]\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "import re\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Encode the image as base64\n",
    "with open(\"user_upload.jpg\", \"rb\") as f:\n",
    "    img_base64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "# Create chat messages\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a meme assistant. Generate a short, funny meme story from the given image. \"\n",
    "            \"Return captions, tags, character, and scam_type in valid JSON format ONLY. \"\n",
    "            \"Do NOT include any explanations, extra text, or emojis. \"\n",
    "            \"The JSON must have keys: caption, tags, character, scam_type. \"\n",
    "            \"If scam_type is not applicable, set it to 'Unknown'.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Generate a meme story for this image.\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{img_base64}\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Call GPT\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Extract raw output\n",
    "raw_output = response.choices[0].message.content\n",
    "\n",
    "# Optional: Extract JSON if GPT wraps it in extra text\n",
    "match = re.search(r\"\\{.*\\}\", raw_output, re.DOTALL)\n",
    "json_text = match.group() if match else \"{}\"\n",
    "\n",
    "# Parse JSON safely\n",
    "try:\n",
    "    result = json.loads(json_text)\n",
    "except json.JSONDecodeError:\n",
    "    result = {\"caption\": raw_output, \"tags\": [], \"character\": \"\", \"scam_type\": \"Unknown\"}\n",
    "\n",
    "# Pretty-print result\n",
    "print(json.dumps(result, indent=4))\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
    "\n",
    "prompt = (\n",
    "    \"You are a scriptwriter for an 8-second meme video.\\n\\n\"\n",
    "    f\"Hereâ€™s the meme data:\\n{result}\\n\\n\"\n",
    "    \"Write a short script for an 8-second video based on this meme. \"\n",
    "    \"Make it funny, clear, and with simple dialogue. \"\n",
    "    \"Return ONLY the script text, no JSON, no metadata.\"\n",
    ")\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "script_text = response.content.strip()\n",
    "print(\"ðŸŽ¬ Generated Script:\\n\", script_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e32778b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤ Narration Text for 11Labs:\n",
      " A notification pops up on the phone saying, \"Unusual activity detected.\" Meanwhile, a cat sits on the phone, looking completely innocent. The cat thinks, \"I just wanted to order more treats.\" Then, a person picks up the phone, shakes their head, and laughs, saying, \"Busted, Mr. Whiskers!\" The scene wraps up with the cat giving a playful meow.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from elevenlabs.client import ElevenLabs\n",
    "from elevenlabs.play import play\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# LLM setup\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# Narration bot prompt\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"You are a narration assistant. Rewrite scripts into smooth, human-like narration \"\n",
    "     \"for a short 8-second video. Keep it conversational and easy for TTS. \"\n",
    "     \"Do NOT include stage directions, emojis, or formatting. Just plain narration text.\"),\n",
    "    (\"user\", \"Convert this script into narration:\\n\\n{script}\")\n",
    "])\n",
    "\n",
    "# Format and run\n",
    "messages = prompt_template.format_messages(script=script_text)\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "narration = response.content.strip()\n",
    "\n",
    "print(\"ðŸŽ¤ Narration Text for 11Labs:\\n\", narration)\n",
    "\n",
    "elevenlabs = ElevenLabs(\n",
    "  api_key=os.getenv(\"ELEVENLABS_API_KEY\"),\n",
    ")\n",
    "\n",
    "audio = elevenlabs.text_to_speech.convert(\n",
    "    text= narration ,\n",
    "    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n",
    "    model_id=\"eleven_multilingual_v2\",\n",
    "    output_format=\"mp3_44100_128\",\n",
    ")\n",
    "\n",
    "play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ce114",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error code: 403 - {'error': 'Model variant gen4_image is not available', 'docUrl': 'https://docs.dev.runwayml.com/api'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionDeniedError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# The env var RUNWAYML_API_SECRET is expected to contain your API key.\u001b[39;00m\n\u001b[32m      4\u001b[39m client = RunwayML()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m task = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage_to_video\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgen4_image\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m  \u001b[49m\u001b[43mprompt_image\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttps://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTZouypNVCAMcyEZHJ_I1l1kiyut3KdrVvkTg&s\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m  \u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mThe bunny is eating a carrot\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m  \u001b[49m\u001b[43mratio\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1280:720\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m.wait_for_task_output()\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(task)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TruthLoop/truthloop/lib/python3.13/site-packages/runwayml/resources/image_to_video.py:124\u001b[39m, in \u001b[36mImageToVideoResource.create\u001b[39m\u001b[34m(self, model, prompt_image, ratio, content_moderation, duration, prompt_text, seed, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m     54\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     55\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m     69\u001b[39m ) -> NewTaskCreatedResponse:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    This endpoint will start a new task to generate a video from an image prompt.\u001b[39;00m\n\u001b[32m     72\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    122\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v1/image_to_video\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_image\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mratio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent_moderation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_moderation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mduration\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimage_to_video_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageToVideoCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcreate_waitable_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mImageToVideoCreateResponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TruthLoop/truthloop/lib/python3.13/site-packages/runwayml/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TruthLoop/truthloop/lib/python3.13/site-packages/runwayml/_base_client.py:1044\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1041\u001b[39m             err.response.read()\n\u001b[32m   1043\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mPermissionDeniedError\u001b[39m: Error code: 403 - {'error': 'Model variant gen4_image is not available', 'docUrl': 'https://docs.dev.runwayml.com/api'}"
     ]
    }
   ],
   "source": [
    "from runwayml import RunwayML\n",
    "\n",
    "# The env var RUNWAYML_API_SECRET is expected to contain your API key.\n",
    "client = RunwayML()\n",
    "\n",
    "task = client.image_to_video.create(\n",
    "  model='gen4_turbo',\n",
    "  prompt_image='https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTZouypNVCAMcyEZHJ_I1l1kiyut3KdrVvkTg&s',\n",
    "  prompt_text='The bunny is eating a carrot',\n",
    "  ratio='1280:720',\n",
    ").wait_for_task_output()\n",
    "\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d679badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When you get a text from your 'bank' but you haven't even opened an account yet. | Tags: scam, phishing, funny, textmessage | Character: Confused User | Scam Type: Phishing\n"
     ]
    }
   ],
   "source": [
    "text_entry = f\"{result['caption']} | Tags: {', '.join(result['tags'])} | Character: {result['character']} | Scam Type: {result['scam_type']}\"\n",
    "print(text_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "628e89fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector = embeddings.embed_query(text_entry) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "901e510f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Meme stored in vector DB\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Initialize or load DB\n",
    "db = Chroma(persist_directory=\"meme_db\", embedding_function=embeddings)\n",
    "\n",
    "# Add the new meme\n",
    "db.add_texts([text_entry])\n",
    "db.persist()\n",
    "\n",
    "print(\"âœ… Meme stored in vector DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import json\n",
    "\n",
    "# Serialize for prompt\n",
    "meme_text = json.dumps(result, indent=4)\n",
    "\n",
    "# Define prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a script writer for 8-second educational meme videos. \"\n",
    "            \"Given the meme JSON, generate a short video script describing the scene, \"\n",
    "            \"character actions, and any dialogue. \"\n",
    "            \"Return output in JSON with keys: 'script', 'duration_seconds'.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Generate a video script from this meme JSON:\\n{meme_text}\"\n",
    "    }\n",
    "])\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# Generate script\n",
    "response = llm(prompt_template.format_prompt().to_messages())\n",
    "\n",
    "# Extract output\n",
    "raw_output = response[0].content\n",
    "\n",
    "# Parse JSON safely\n",
    "try:\n",
    "    script_result = json.loads(raw_output)\n",
    "except json.JSONDecodeError:\n",
    "    script_result = {\"script\": raw_output, \"duration_seconds\": 8}\n",
    "\n",
    "# Print generated video script\n",
    "print(json.dumps(script_result, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b142d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_caption = \"A dog holding a pizza slice like a phone\"\n",
    "db.add_texts([new_caption])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"A person holding a bag of free money\"\n",
    "results = db.similarity_search(query, k=3)\n",
    "for r in results:\n",
    "    print(r.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e6f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"A person holding a bag of free money\"\n",
    "results = db.similarity_search(query, k=3)\n",
    "for r in results:\n",
    "    print(r.page_content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "truthloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
